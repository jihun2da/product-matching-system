# -*- coding: utf-8 -*-
"""
perfect_matcher.py
ì„¤ì • ë¶„ë¦¬í˜• êµ¬ì¡°
- config.pyì—ì„œ ëª¨ë“  ì„¤ì •ì„ ë¶ˆëŸ¬ì™€ ì‚¬ìš©
- ê³ ì† ë§¤ì¹­(ë¸”ë¡œí‚¹+ë²¡í„°í™”) + ìƒí’ˆëª…/ì‚¬ì´ì¦ˆ ìºë…¼í™” + ìƒ‰ìƒ ì •ê·œí™”
- ì—‘ì…€ ìƒ‰ìƒ ì ìš©/ê°€ê²© ë¹„êµ/ê²°ê³¼ ì €ì¥ í¬í•¨
"""

import re
import time
import logging
import unicodedata
from dataclasses import dataclass
from typing import List, Tuple, Dict, Optional, Any, Set
from collections import defaultdict

import pandas as pd
from rapidfuzz import fuzz, process
from tqdm import tqdm
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# ---- ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° ----
from config import (
    DEFAULT_PATHS,
    NAME_SYNONYM_GROUPS,
    SIZE_SYNONYMS,
    COLOR_ALIASES,
    EXCEL_COLORS,
    MATCHING,
    LOGGING,
    PERFORMANCE,
)

# ----------------------------------
# ë¡œê¹… ì„¸íŒ…
# ----------------------------------
logging.basicConfig(
    level=getattr(logging, LOGGING.get("level", "INFO")),
    format="%(asctime)s | %(levelname)s | %(message)s"
)
logger = logging.getLogger("matcher")

# ----------------------------------
# ê²°ê³¼ êµ¬ì¡°
# ----------------------------------
@dataclass
class MatchResult:
    receipt_idx: int
    matched_idx: int
    confidence_score: float
    match_details: Dict[str, Any]

# ----------------------------------
# ìœ í‹¸
# ----------------------------------
def make_fill(argb_hex: str) -> PatternFill:
    """ARGB 8ìë¦¬ HEXë¡œ PatternFill ìƒì„±"""
    code = argb_hex.upper()
    if len(code) != 8:
        raise ValueError(f"ì—‘ì…€ ìƒ‰ìƒ ì½”ë“œëŠ” ARGB 8ìë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤: '{argb_hex}'")
    return PatternFill(start_color=code, end_color=code, fill_type="solid")

# ----------------------------------
# ë§¤ì¹­ ì—”ì§„
# ----------------------------------
class PerfectMatcher:
    def __init__(self):
        # configì—ì„œ ì½ì€ ê°’ ë³´ê´€
        self.name_score_cutoff: int = MATCHING.get("name_score_cutoff", 70)
        w = MATCHING.get("weights", {"brand": 0.25, "name": 0.35, "color": 0.25, "size": 0.15})
        self.weight_brand = float(w.get("brand", 0.25))
        self.weight_name  = float(w.get("name",  0.35))
        self.weight_color = float(w.get("color", 0.25))
        self.weight_size  = float(w.get("size",  0.15))

        self.progress_update_every = PERFORMANCE.get("progress_update_every", 50)

    # ---------- ì •ê·œí™” ìœ í‹¸ ----------
    def normalize_text_ultra(self, s: str) -> str:
        """ë¸Œëœë“œ/ìƒí’ˆëª…ìš© ê°•ë ¥ ì •ê·œí™” (ì†Œë¬¸ìí™”, ê¸°í˜¸ ì œê±°, ê³µë°± ì •ë¦¬)"""
        if not isinstance(s, str):
            s = "" if pd.isna(s) else str(s)
        s = s.strip()
        s = unicodedata.normalize("NFKC", s)
        s = s.lower()
        s = re.sub(r"\s+", " ", s)
        # í•œ/ì˜/ìˆ«ì ì™¸ëŠ” ê³µë°±ìœ¼ë¡œ ì¹˜í™˜ â†’ ë¶™ì€ ì•½ì–´ë„ ê³µë°± ë¶„ë¦¬ë¨ (ì˜ˆ: ë³¼mtm â†’ 'ë³¼ mtm')
        s = re.sub(r"[^0-9a-zê°€-í£]+", " ", s)
        s = re.sub(r"\s+", " ", s).strip()
        return s

    def normalize_color_ultra(self, s: str) -> str:
        """ìƒ‰ìƒ ì „ìš© ì •ê·œí™”(ì„¤ì •ì˜ COLOR_ALIASES ë°˜ì˜)"""
        s = self.normalize_text_ultra(s)
        tokens = s.split()
        mapped = [COLOR_ALIASES.get(t, t) for t in tokens]
        return " ".join(mapped)

    # ====== ì‚¬ì´ì¦ˆ/ìƒí’ˆëª… ìºë…¼í™” ìœ í‹¸ ======
    def _normalize_size_token(self, tok: str) -> str:
        """ì‚¬ì´ì¦ˆ í† í°ì„ ìºë…¼ ë¼ë²¨ë¡œ í†µì¼. ì˜ˆ: '2xl' -> 'xxl'"""
        t = tok.lower()
        for canon, variants in SIZE_SYNONYMS.items():
            if t == canon or t in variants:
                return canon
        return t

    def apply_bidir_synonyms_text(self, normalized_text: str) -> str:
        """
        normalize_text_ultra() ì´í›„ì˜ ë¬¸ìì—´ì—
        NAME_SYNONYM_GROUPSë¥¼ ì ìš©í•´ ìºë…¼ ë¼ë²¨ë¡œ í†µì¼.
        - ëŒ€/ì†Œë¬¸ì ë¬´ì‹œ
        - ë‹¨ì–´ ì•ˆì— ì„ì—¬ ìˆì–´ë„(í¬í•¨ì¹˜í™˜) ì¹˜í™˜
        """
        if not normalized_text:
            return normalized_text
        s = normalized_text
        for canon, variants in NAME_SYNONYM_GROUPS.items():
            for v in variants:
                s = re.sub(re.escape(v), canon, s, flags=re.IGNORECASE)
        return s

    def _extract_parentheses_values(self, size_token: str) -> Set[str]:
        """
        ê´„í˜¸ê°€ í¬í•¨ëœ ì‚¬ì´ì¦ˆì—ì„œ ê´„í˜¸ ì•ˆíŒ ê°’ì„ ê°ê° ì¶”ì¶œ
        ì˜ˆ: '7(M)' -> {'7', 'M'}, 'M(9)' -> {'M', '9'}, 'L' -> {'L'}
        """
        values = set()
        
        # ê´„í˜¸ íŒ¨í„´ ë§¤ì¹­: ê´„í˜¸ ë°–(ê´„í˜¸ ì•ˆ) í˜•íƒœ
        parentheses_match = re.match(r'^([^()]+)\(([^()]+)\)$', size_token)
        if parentheses_match:
            outside = parentheses_match.group(1).strip()
            inside = parentheses_match.group(2).strip()
            if outside:
                values.add(outside)
            if inside:
                values.add(inside)
        else:
            # ê´„í˜¸ê°€ ì—†ëŠ” ê²½ìš° ê·¸ëŒ€ë¡œ ì¶”ê°€
            if size_token:
                values.add(size_token)
        
        return values

    def extract_size_parts_ultra(self, s: str) -> Set[str]:
        """
        ì‚¬ì´ì¦ˆë¥¼ í† í°ì…‹ìœ¼ë¡œ ì¶”ì¶œ(S~XL, 5í˜¸, 110, free ë“±)
        - í† í° ìºë…¼í™”: 2xl â†’ xxl ë“±
        - ê´„í˜¸ ì•ˆíŒ ê°’ ë¶„ë¦¬: 7(M) -> {7, M}
        """
        if not isinstance(s, str):
            s = "" if pd.isna(s) else str(s)
        s = unicodedata.normalize("NFKC", s)
        s = s.replace("~", " ~ ")
        s = re.sub(r"[,/|]+", " ", s)
        s = re.sub(r"\s+", " ", s).strip().lower()

        tokens = set()
        for tok in s.split():
            # ê¸°ë³¸ ì •ë¦¬ (íŠ¹ìˆ˜ë¬¸ì ì œê±°ëŠ” ê´„í˜¸ ì²˜ë¦¬ í›„ì—)
            tok = tok.strip()
            if not tok:
                continue
            
            # ê´„í˜¸ ì•ˆíŒ ê°’ ì¶”ì¶œ
            parentheses_values = self._extract_parentheses_values(tok)
            
            for value in parentheses_values:
                # ê° ê°’ì— ëŒ€í•´ ì •ë¦¬ ë° ìºë…¼í™” ì ìš©
                cleaned_value = re.sub(r"[^0-9a-zê°€-í£]+", "", value)
                if cleaned_value:
                    normalized_value = self._normalize_size_token(cleaned_value)  # â˜… ì‚¬ì´ì¦ˆ ìºë…¼í™”
                    tokens.add(normalized_value)
        
        return tokens

    # ---------- í¼ì§€ ----------
    def fast_fuzzy_match(self, a: str, b: str) -> float:
        """ìƒí’ˆëª… ë§¤ì¹­ìš© ê²½ëŸ‰ í¼ì§€(ë¶€ë¶„ë¹„êµ)"""
        if not a or not b:
            return 0.0
        return float(fuzz.partial_ratio(a, b))

    # ---------- ì‹ ë¢°ë„ ê³„ì‚°(ì¡°ê¸°ì¢…ë£Œ ì ìš©) ----------
    def calculate_match_confidence_perfect(self, receipt_row: pd.Series, matched_row: pd.Series):
        try:
            # ì •ê·œí™” ì»¬ëŸ¼ ìš°ì„  ì‚¬ìš©
            rb = receipt_row.get("r_brand_n") or self.normalize_text_ultra(receipt_row.get("ë¸Œëœë“œ", ""))
            rn = receipt_row.get("r_name_n")  or self.normalize_text_ultra(receipt_row.get("ìƒí’ˆëª…", ""))
            rc = receipt_row.get("r_color_n") or self.normalize_color_ultra(receipt_row.get("ìƒ‰ìƒ", ""))
            rs = receipt_row.get("r_sizes_s")
            if rs is None:
                rs = self.extract_size_parts_ultra(receipt_row.get("ì‚¬ì´ì¦ˆ", ""))

            mb = matched_row.get("m_brand_n") or self.normalize_text_ultra(matched_row.get("ë¸Œëœë“œ", ""))
            mn = matched_row.get("m_name_n")  or self.normalize_text_ultra(matched_row.get("ìƒí’ˆëª…", ""))
            mc = matched_row.get("m_color_n") or self.normalize_color_ultra(matched_row.get("ìƒ‰ìƒ", ""))
            ms = matched_row.get("m_sizes_s")
            if ms is None:
                ms = self.extract_size_parts_ultra(matched_row.get("ì‚¬ì´ì¦ˆ", ""))

            # 1) ì €ë¹„ìš© í™•ì • ì²´í¬
            if not rs or not ms or len(rs.intersection(ms)) == 0:
                return False, 0.0, {}
            if rb != mb:
                return False, 0.0, {}
            if rc != mc:
                return False, 0.0, {}

            # 2) ìƒí’ˆëª… í¼ì§€ (ë¸Œëœë“œ/ìƒ‰ìƒ/ì‚¬ì´ì¦ˆëŠ” í™•ì • í†µê³¼)
            name_score = self.fast_fuzzy_match(rn, mn)
            if name_score < self.name_score_cutoff:
                return False, 0.0, {}

            # ìµœì¢… ê°€ì¤‘í•©
            brand_score = 100.0
            color_score = 100.0
            size_score  = 100.0
            total_conf = (
                brand_score * self.weight_brand +
                name_score  * self.weight_name  +
                color_score * self.weight_color +
                size_score  * self.weight_size
            )

            details = {
                "brand_match": True, "brand_score": brand_score,
                "name_match": True,  "name_score": name_score,
                "color_match": True, "color_score": color_score,
                "size_match": True,  "size_score": size_score
            }
            return True, float(total_conf), details

        except Exception as e:
            logger.exception(f"ë§¤ì¹­ ì‹ ë¢°ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return False, 0.0, {}

    # ---------- ì‚¬ì „ì •ê·œí™”/ì¸ë±ìŠ¤ ----------
    def _precompute_normalized_columns(self, df: pd.DataFrame, prefix: str) -> pd.DataFrame:
        brand = df.get("ë¸Œëœë“œ", "").fillna("")
        name  = df.get("ìƒí’ˆëª…", "").fillna("")
        color = df.get("ìƒ‰ìƒ", "").fillna("")
        size  = df.get("ì‚¬ì´ì¦ˆ", "").fillna("")

        df[f"{prefix}_brand_n"] = [self.normalize_text_ultra(x) for x in brand]

        # 1ì°¨ ì •ê·œí™” â†’ 2ì°¨ ë™ì˜ì–´ ìºë…¼í™”(ìƒí’ˆëª…)
        name_n = [self.normalize_text_ultra(x) for x in name]
        name_n = [self.apply_bidir_synonyms_text(x) for x in name_n]
        df[f"{prefix}_name_n"] = name_n

        df[f"{prefix}_color_n"] = [self.normalize_color_ultra(x) for x in color]
        df[f"{prefix}_sizes_s"] = [self.extract_size_parts_ultra(x) for x in size]
        return df

    def _build_candidate_index(self, matched_df: pd.DataFrame):
        idx_bcs, idx_bc, idx_b = defaultdict(list), defaultdict(list), defaultdict(list)
        for midx, row in matched_df.iterrows():
            b = row["m_brand_n"]; c = row["m_color_n"]; sizes = row["m_sizes_s"]
            idx_b[(b,)].append(midx)
            idx_bc[(b, c)].append(midx)
            if sizes:
                for s in sizes:
                    idx_bcs[(b, c, s)].append(midx)
        return idx_bcs, idx_bc, idx_b

    # ---------- ë¹ ë¥¸ ë§¤ì¹­ê¸° ----------
    def fuzzy_match_orders_blocked(self, receipt_df: pd.DataFrame, matched_df: pd.DataFrame) -> List[MatchResult]:
        logger.info(f"[FAST] ë¸”ë¡œí‚¹+ë²¡í„°í™” ë§¤ì¹­ ì‹œì‘: R={len(receipt_df)}, M={len(matched_df)}")

        receipt_df = self._precompute_normalized_columns(receipt_df.copy(), "r")
        matched_df = self._precompute_normalized_columns(matched_df.copy(), "m")

        idx_bcs, idx_bc, idx_b = self._build_candidate_index(matched_df)

        matched_results: List[MatchResult] = []
        receipt_qty = {idx: int(receipt_df.at[idx, "ìˆ˜ëŸ‰"]) if "ìˆ˜ëŸ‰" in receipt_df.columns else 1
                       for idx in receipt_df.index}
        matched_qty = {idx: int(matched_df.at[idx, "ìˆ˜ëŸ‰"]) if "ìˆ˜ëŸ‰" in matched_df.columns else 1
                       for idx in matched_df.index}

        update_every = max(self.progress_update_every, len(receipt_df)//50 or 1)

        with tqdm(total=len(receipt_df), desc="âš¡ FAST ë§¤ì¹­", unit="ê±´",
                  bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]") as pbar:

            for r_idx, r_row in receipt_df.iterrows():
                remain = receipt_qty.get(r_idx, 1)
                if remain <= 0:
                    if (len(matched_results) % update_every) == 0:
                        pbar.set_postfix_str(f"matches={len(matched_results)}")
                    pbar.update(1)
                    continue

                b = r_row["r_brand_n"]; c = r_row["r_color_n"]; sizes = r_row["r_sizes_s"]
                candidate_ids: List[int] = []

                # 1ìˆœìœ„: (b,c,ì‚¬ì´ì¦ˆ)
                if sizes:
                    for s in sizes:
                        candidate_ids.extend(idx_bcs.get((b, c, s), []))
                # 2ìˆœìœ„: (b,c)
                if not candidate_ids:
                    candidate_ids.extend(idx_bc.get((b, c), []))
                # 3ìˆœìœ„: (b)
                if not candidate_ids:
                    candidate_ids.extend(idx_b.get((b,), []))

                # ì¬ê³  ìˆëŠ” ê²ƒë§Œ
                candidate_ids = [mid for mid in candidate_ids if matched_qty.get(mid, 0) > 0]
                if not candidate_ids:
                    if (len(matched_results) % update_every) == 0:
                        pbar.set_postfix_str(f"matches={len(matched_results)}")
                    pbar.update(1)
                    continue

                # í¼ì§€ë§¤ì¹­(ìƒí’ˆëª…ë§Œ) - ë²¡í„°í™” í˜¸ì¶œ
                r_name = r_row["r_name_n"]
                cand_names = [matched_df.at[mid, "m_name_n"] for mid in candidate_ids]

                scored = process.extract(
                    r_name,
                    cand_names,
                    scorer=fuzz.partial_ratio,
                    score_cutoff=self.name_score_cutoff,
                    limit=None
                )

                if not scored:
                    if (len(matched_results) % update_every) == 0:
                        pbar.set_postfix_str(f"matches={len(matched_results)}")
                    pbar.update(1)
                    continue

                # ì‹ ë¢°ë„ í‰ê°€ + ì •ë ¬
                results: List[Tuple[int, float, Dict[str, Any]]] = []
                for _, _, local_idx in scored:
                    m_idx = candidate_ids[local_idx]
                    ok, conf, details = self.calculate_match_confidence_perfect(
                        receipt_row=r_row, matched_row=matched_df.loc[m_idx]
                    )
                    if ok:
                        results.append((m_idx, conf, details))

                if results:
                    results.sort(key=lambda x: x[1], reverse=True)

                    for m_idx, conf, details in results:
                        if remain <= 0:
                            break
                        if matched_qty[m_idx] <= 0:
                            continue

                        match_qty = min(remain, matched_qty[m_idx])
                        for _ in range(int(match_qty)):
                            matched_results.append(
                                MatchResult(receipt_idx=r_idx, matched_idx=m_idx,
                                            confidence_score=conf, match_details=details)
                            )
                        receipt_qty[r_idx] -= match_qty
                        matched_qty[m_idx] -= match_qty
                        remain -= match_qty

                if (len(matched_results) % update_every) == 0:
                    pbar.set_postfix_str(f"matches={len(matched_results)}")
                pbar.update(1)

        logger.info(f"[FAST] ì™„ë£Œ: {len(matched_results)}ê±´")
        return matched_results

    # ---------- ëŠë¦° ë§¤ì¹­ê¸°(ë ˆí¼ëŸ°ìŠ¤) ----------
    def fuzzy_match_orders_perfect_sequential(self, receipt_df: pd.DataFrame, matched_df: pd.DataFrame) -> List[MatchResult]:
        logger.info(f"[SLOW] ìˆœì°¨ í¼ì§€ ë§¤ì¹­ ì‹œì‘: R={len(receipt_df)}, M={len(matched_df)}")
        matched_results: List[MatchResult] = []
        receipt_qty = {idx: int(receipt_df.at[idx, "ìˆ˜ëŸ‰"]) if "ìˆ˜ëŸ‰" in receipt_df.columns else 1
                       for idx in receipt_df.index}
        matched_qty = {idx: int(matched_df.at[idx, "ìˆ˜ëŸ‰"]) if "ìˆ˜ëŸ‰" in matched_df.columns else 1
                       for idx in matched_df.index}

        with tqdm(total=len(receipt_df), desc="ğŸ¢ SLOW ë§¤ì¹­", unit="ê±´") as pbar:
            for r_idx, r_row in receipt_df.iterrows():
                remain = receipt_qty.get(r_idx, 1)
                if remain <= 0:
                    pbar.update(1)
                    continue

                candidates = []
                for m_idx, m_row in matched_df.iterrows():
                    ok, conf, details = self.calculate_match_confidence_perfect(r_row, m_row)
                    if ok and matched_qty.get(m_idx, 0) > 0:
                        candidates.append((m_idx, conf, details))

                candidates.sort(key=lambda x: x[1], reverse=True)

                for m_idx, conf, details in candidates:
                    if remain <= 0:
                        break
                    if matched_qty[m_idx] <= 0:
                        continue

                    match_qty = min(remain, matched_qty[m_idx])
                    for _ in range(int(match_qty)):
                        matched_results.append(
                            MatchResult(receipt_idx=r_idx, matched_idx=m_idx,
                                        confidence_score=conf, match_details=details)
                        )
                    receipt_qty[r_idx] -= match_qty
                    matched_qty[m_idx] -= match_qty
                    remain -= match_qty

                pbar.update(1)

        logger.info(f"[SLOW] ì™„ë£Œ: {len(matched_results)}ê±´")
        return matched_results


# ----------------------------------
# ìƒ‰ìƒ ì ìš© + íŒŒì¼ ì €ì¥ í¬í•¨í•œ ì†”ë£¨ì…˜
# ----------------------------------
class PerfectSolutionMatcher(PerfectMatcher):

    def apply_colors_with_quantity_enhanced(
        self,
        receipt_path: str,
        matched_path: str,
        output_receipt: str,
        output_matched: str,
        match_results: List[MatchResult],
        receipt_df: pd.DataFrame,
        matched_df: pd.DataFrame,
    ) -> None:
        """
        ë§¤ì¹­ ìŒ ê¸°ì¤€ìœ¼ë¡œ
        - Receipt ì›Œí¬ë¶: A~E ì»¬ëŸ¬ ì±„ìš°ê¸°, F(ê¸ˆì•¡) ê°€ê²© ë¹„êµ ì‹œ ë¹¨ê°„ìƒ‰ í‘œì‹œ
        - Matched  ì›Œí¬ë¶: H~N ì»¬ëŸ¬ ì±„ìš°ê¸°, N(14ì—´) ë¹„êµ í‘œì‹œ
        - Gì—´ ê°’ì´ TRUEë©´ ì‹œì•ˆ, ì•„ë‹ˆë©´ ë…¸ë‘
        - H~N ë²”ìœ„ ì´ˆê¸°í™” ë° ë§¤ì¹­ ì •ë³´ ê¸°ë¡ì€ _update_match_info ì—ì„œ ìˆ˜í–‰
        """
        # ì›Œí¬ë¶ ë¡œë“œ
        receipt_wb = load_workbook(receipt_path)
        matched_wb = load_workbook(matched_path)

        receipt_ws = receipt_wb.active
        matched_ws = matched_wb.active

        # ì±„ìš°ê¸° ìƒ‰ (configì—ì„œ ë¶ˆëŸ¬ì™€ ìƒì„±)
        cyan_fill   = make_fill(EXCEL_COLORS["cyan"])
        yellow_fill = make_fill(EXCEL_COLORS["yellow"])
        red_fill    = make_fill(EXCEL_COLORS["red"])

        # ë§¤ì¹­ ìŒ êµ¬ì„± (ìˆ˜ëŸ‰ë§Œí¼ ì¤‘ë³µ í¬í•¨)
        matched_pairs: List[Tuple[int, int]] = [(r.receipt_idx, r.matched_idx) for r in match_results]

        # ìƒ‰ìƒ ì ìš©
        with tqdm(
            matched_pairs,
            desc="ğŸ¨ ìƒ‰ìƒ ì ìš©",
            unit="ìŒ",
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]"
        ) as pbar:
            for receipt_idx, matched_idx in pbar:
                try:
                    # Gì—´(7) ê°’ìœ¼ë¡œ êµ¬ë¶„
                    g_value = receipt_ws.cell(row=receipt_idx + 2, column=7).value
                    fill_color = cyan_fill if str(g_value).strip().upper() == "TRUE" else yellow_fill

                    # Receipt íŒŒì¼ ìƒ‰ìƒ: A(1)~E(5)
                    for col in range(1, 6):
                        receipt_ws.cell(row=receipt_idx + 2, column=col).fill = fill_color

                    # Matched íŒŒì¼ ìƒ‰ìƒ: H(8)~N(14)
                    for col in range(8, 14 + 1):
                        matched_ws.cell(row=matched_idx + 2, column=col).fill = fill_color

                    # ê°€ê²© ë¹„êµ
                    try:
                        receipt_price = float(receipt_df.loc[receipt_idx, "ê¸ˆì•¡"])
                        matched_price = float(matched_df.loc[matched_idx, "ë„ë§¤ê°€"]) * \
                                        float(receipt_df.loc[receipt_idx, "ìˆ˜ëŸ‰"])
                        if receipt_price != matched_price:
                            receipt_ws.cell(row=receipt_idx + 2, column=6).fill = red_fill   # Fì—´
                            matched_ws.cell(row=matched_idx + 2, column=14).fill = red_fill # Nì—´(14)
                        else:
                            receipt_ws.cell(row=receipt_idx + 2, column=6).fill = fill_color
                            matched_ws.cell(row=matched_idx + 2, column=14).fill = fill_color
                    except Exception as pe:
                        logger.warning(f"ê°€ê²© ë¹„êµ ìŠ¤í‚µ (í–‰ r{receipt_idx} m{matched_idx}): {pe}")

                except Exception as e:
                    logger.error(f"ìƒ‰ìƒ ì ìš© ì˜¤ë¥˜ (í–‰ {receipt_idx}-{matched_idx}): {e}")
                    continue

        # H~N ì´ˆê¸°í™” + ë§¤ì¹­ì •ë³´ ì—…ë°ì´íŠ¸ (Receipt ì›Œí¬ë¶)
        self._update_match_info(receipt_ws, matched_pairs, matched_df)

        # ì €ì¥
        receipt_wb.save(output_receipt)
        matched_wb.save(output_matched)
        logger.info(f"ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_receipt}, {output_matched}")

    def _update_match_info(self, receipt_ws, matched_pairs: List[Tuple[int, int]], matched_df: pd.DataFrame) -> None:
        """
        Hì—´~Nì—´ ì´ˆê¸°í™” ë° ë§¤ì¹­ ì •ë³´ ì—…ë°ì´íŠ¸
        - Hì—´: "ìƒí’ˆëª… / ì‚¬ì´ì¦ˆ"
        - Iì—´~: ë§¤ì¹­ëœ ê¸°ì¤€ë°ì´í„°ì˜ í–‰ë²ˆí˜¸(actual_row_number) ëˆ„ì  ê¸°ì…
        """
        try:
            # ì´ˆê¸°í™”
            for row in range(2, receipt_ws.max_row + 1):
                for col in range(8, 15):  # H(8) ~ N(14)
                    receipt_ws.cell(row=row, column=col).value = None

            match_count: Dict[int, int] = defaultdict(int)

            for receipt_idx, matched_idx in matched_pairs:
                row_excel = receipt_idx + 2

                # ê¸°ì¤€ë°ì´í„° ìš”ì•½ í…ìŠ¤íŠ¸
                matched_product_name = matched_df.loc[matched_idx, "ìƒí’ˆëª…"] if "ìƒí’ˆëª…" in matched_df.columns else ""
                matched_size = matched_df.loc[matched_idx, "ì‚¬ì´ì¦ˆ"] if "ì‚¬ì´ì¦ˆ" in matched_df.columns else ""
                matched_info = f"{matched_product_name} / {matched_size}".strip(" /")

                current_col_offset = match_count[receipt_idx]
                target_col = 9 + current_col_offset  # Iì—´(9)ë¶€í„° ì˜¤ë¥¸ìª½ìœ¼ë¡œ

                if current_col_offset == 0:
                    receipt_ws.cell(row=row_excel, column=8).value = matched_info  # Hì—´

                actual_row_number = matched_idx + 2  # ê¸°ì¤€ íŒŒì¼ì˜ ì‹¤ì œ ì—‘ì…€ í–‰ë²ˆí˜¸
                if target_col <= 14:
                    receipt_ws.cell(row=row_excel, column=target_col).value = actual_row_number

                match_count[receipt_idx] += 1

        except Exception as e:
            logger.error(f"ë§¤ì¹­ ì •ë³´ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")

    # ---------- ì—”ë“œ-íˆ¬-ì—”ë“œ ----------
    def process_excel_perfect_solution(
        self,
        receipt_path: str,
        matched_path: str,
        output_receipt: str,
        output_matched: str,
        use_fast: bool = True
    ) -> Tuple[int, List[MatchResult]]:
        """
        íŒŒì¼ ì½ê¸° â†’ ë§¤ì¹­(ë¹ ë¥¸/ëŠë¦°) â†’ ìƒ‰ìƒ ì ìš© & ì €ì¥ â†’ ë¦¬í¬íŠ¸ ë¡œê·¸
        return: (ë§¤ì¹­ê±´ìˆ˜, match_results)
        """
        start_time = time.time()
        logger.info("ğŸ¯ ì™„ë²½í•œ í•´ê²°ì±… ì²˜ë¦¬ ì‹œì‘")

        # 1) íŒŒì¼ ì½ê¸°
        read_start = time.time()
        logger.info("ğŸ“– íŒŒì¼ ì½ê¸° ì¤‘...")
        receipt_df = pd.read_excel(receipt_path, engine="openpyxl")
        matched_df = pd.read_excel(matched_path, engine="openpyxl")
        read_time = time.time() - read_start
        logger.info(f"ğŸ“– íŒŒì¼ ì½ê¸° ì™„ë£Œ - Receipt: {len(receipt_df)}í–‰, Matched: {len(matched_df)}í–‰ ({read_time:.2f}ì´ˆ)")

        # 2) ë§¤ì¹­
        match_start = time.time()
        if use_fast:
            match_results = self.fuzzy_match_orders_blocked(receipt_df, matched_df)
        else:
            match_results = self.fuzzy_match_orders_perfect_sequential(receipt_df, matched_df)
        match_time = time.time() - match_start

        # 3) ìƒ‰ìƒ ì ìš© + ì €ì¥
        color_start = time.time()
        self.apply_colors_with_quantity_enhanced(
            receipt_path, matched_path, output_receipt, output_matched,
            match_results, receipt_df, matched_df
        )
        color_time = time.time() - color_start

        total_time = time.time() - start_time
        logger.info("ğŸ¯ ì™„ë²½í•œ í•´ê²°ì±… ì™„ë£Œ:")
        logger.info(f"  â”œâ”€ ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ")
        logger.info(f"  â”œâ”€ íŒŒì¼ ì½ê¸°: {read_time:.2f}ì´ˆ")
        logger.info(f"  â”œâ”€ ë§¤ì¹­ ì²˜ë¦¬: {match_time:.2f}ì´ˆ")
        logger.info(f"  â””â”€ ìƒ‰ìƒ ì ìš©: {color_time:.2f}ì´ˆ")
        logger.info(f"  ğŸ“Š ë§¤ì¹­ ê±´ìˆ˜: {len(match_results)}ê±´")

        return len(match_results), match_results

    def generate_match_report(self, match_results: List[MatchResult]) -> Dict[str, Any]:
        if not match_results:
            return {"total_matches": 0, "average_confidence": 0, "match_distribution": {}}

        total = len(match_results)
        avg = sum(mr.confidence_score for mr in match_results) / total if total else 0.0
        high = sum(1 for mr in match_results if mr.confidence_score >= 90)
        mid  = sum(1 for mr in match_results if 70 <= mr.confidence_score < 90)
        low  = sum(1 for mr in match_results if mr.confidence_score < 70)

        report = {
            "total_matches": total,
            "average_confidence": avg,
            "match_distribution": {
                "high_confidence": high,
                "medium_confidence": mid,
                "low_confidence": low
            }
        }
        logger.info(f"ë§¤ì¹­ ë¦¬í¬íŠ¸: {report}")
        return report


# ----------------------------------
# ë©”ì¸ ì‹¤í–‰ ì˜ˆì‹œ
# ----------------------------------
def main():
    print("ğŸ† RapidFuzz ì™„ë²½í•´ê²°ì±… (ì„¤ì • ë¶„ë¦¬í˜•)")
    print("ğŸ¯ ê³ ì† ë§¤ì¹­ + ë™ì˜ì–´/ì•½ì–´ ìºë…¼í™” + ì—‘ì…€ ìƒ‰ìƒ ì ìš©/ì €ì¥")
    print("=" * 70)

    matcher = PerfectSolutionMatcher()

    receipt_path = DEFAULT_PATHS["receipt"]
    matched_path = DEFAULT_PATHS["matched"]
    output_receipt = DEFAULT_PATHS["output_receipt"]
    output_matched = DEFAULT_PATHS["output_matched"]

    matched_count, match_results = matcher.process_excel_perfect_solution(
        receipt_path, matched_path, output_receipt, output_matched, use_fast=True
    )

    report = matcher.generate_match_report(match_results)

    print("\n" + "=" * 70)
    print("ğŸ† ê²°ê³¼ ìš”ì•½")
    print("=" * 70)
    print(f"âœ… ì´ ë§¤ì¹­ ê±´ìˆ˜: {matched_count:,}ê±´")
    print(f"ğŸ“Š í‰ê·  ì‹ ë¢°ë„: {report['average_confidence']:.2f}%")
    print(f"ğŸ“ˆ ê³ ì‹ ë¢°ë„: {report['match_distribution']['high_confidence']:,}ê±´")
    print(f"ğŸ“‰ ì¤‘ì‹ ë¢°ë„: {report['match_distribution']['medium_confidence']:,}ê±´")
    print(f"ğŸ“‰ ì €ì‹ ë¢°ë„: {report['match_distribution']['low_confidence']:,}ê±´")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
